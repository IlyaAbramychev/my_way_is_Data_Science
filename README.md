# Специалист по Data Science

Данные проекты были выполнены в ходе обучения в Яндекс.Практикуме, профессии "Специалист по Data Science".

## Содержание

1. [Музыка больших городов](#1-музыка-больших-городов)
2. [Исследование надежности заемщиков](#2-исследование-надежности-заемщиков)
3. [Исследование объявлений о продаже квартир](#3-исследование-объявлений-о-продаже-квартир)
4. [Статистический анализ данных](#4-статистический-анализ-данных)
5. [Анализ факторов успеха видеоигр](#5-анализ-факторов-успеха-видеоигр)
6. [Прогнозная модель «ЭкоФерма» для отбора буренок](#6-прогнозная-модель-экоферма-для-отбора-буренок)
7. [Персонализация предложений постоянным клиентам](#7-персонализация-предложений-постоянным-клиентам)
8. [Предсказание удовлетворенности сотрудников и их увольнения](#8-предсказание-удовлетворенности-сотрудников-и-их-увольнения)
9. [Выбор локации для скважины](#9-выбор-локации-для-скважины)
10. [Определение стоимости автомобилей](#10-определение-стоимости-автомобилей)
11. [Прогнозирование заказов такси](#11-прогнозирование-заказов-такси)
12. [Классификация токсичных комментариев (Викишоп)](#12-классификация-токсичных-комментариев-викишоп)
13. [Определение возраста покупателей](#13-определение-возраста-покупателей)
14. [Прогноз оттока клиентов телеком-оператора (ТелеДом)](#15-прогноз-оттока-клиентов-телеком-оператора-теледом)
    
---

## Обзор проектов

| № | Название проекта | Описание | Используемые библиотеки |
| :-: | :---------------------- | :---------------------- | :---------------------- |
| 1 | [Музыка больших городов](1_big_cities_music) | Сравнение предпочтений пользователей Яндекс.Музыки из Москвы и Санкт-Петербурга по времени суток и дням недели. | `pandas` |
| 2 | [Исследование надежности заемщиков](2_analysis_of_bank_data) | Анализ банковских данных для выявления зависимостей между семейным положением, количеством детей, уровнем дохода и своевременным возвратом кредита. | `pandas`, `matplotlib` |
| 3 | [Исследование объявлений о продаже квартир](3_real_estate_analysis) | Определение рыночной стоимости недвижимости на основе данных Яндекс Недвижимость и построение системы для обнаружения аномалий и мошенничества. | `pandas`, `matplotlib` |
| 4 | [Статистический анализ данных](4_statistical_data_analysis) | Анализ данных о пользователях, их поездках и подписках для выявления ключевых тенденций и закономерностей. | `numpy`, `pandas`, `scipy`, `matplotlib` |
| 5 | [Анализ факторов успеха видеоигр](5_video_game_success_analysis) | Выявление факторов, определяющих успешность видеоигр, для прогнозирования их популярности и планирования рекламных кампаний. | `pandas`, `matplotlib`, `seaborn`, `numpy`, `scipy` |
| 6 | [Прогнозная модель «ЭкоФерма» для отбора буренок](6_eco_farm_model) | Разработка моделей для прогнозирования удоя коров и оценки качества молока для оптимизации закупок буренок. | `numpy`, `pandas`, `matplotlib`, `seaborn`, `sklearn`, `statsmodels` |
| 7 | [Персонализация предложений постоянным клиентам](7_customer_personalization) | Разработка решения для персонализации предложений клиентам интернет-магазина с целью увеличения их активности. | `pandas`, `numpy`, `shap`, `phik`, `sklearn`, `seaborn`, `matplotlib` |
| 8 | [Предсказание удовлетворенности сотрудников и их увольнения](8_employee_satisfaction_prediction) | Построение моделей для предсказания уровня удовлетворённости сотрудников и вероятности их увольнения. | `pandas`, `numpy`, `sklearn`, `seaborn`, `matplotlib`, `phik` |
| 9 | [Выбор локации для скважины](#9-выбор-локации-для-скважины) | Разработка модели машинного обучения для предсказания объёма запасов нефти в скважинах и выбор региона для бурения на основе расчёта прибыли и оценки рисков. | `pandas`, `numpy`, `sklearn`, `matplotlib`, `seaborn`, `scipy` |
| 10| [Определение стоимости автомобилей](#10-определение-стоимости-автомобилей) | Разработка модели для прогнозирования рыночной стоимости автомобилей на основе их характеристик, комплектации и пробега. | `pandas`, `numpy`, `sklearn`, `matplotlib`, `seaborn`, `LightGBM` |
| 11| [Прогнозирование заказов такси](#11-прогнозирование-заказов-такси) | Разработка модели для предсказания количества заказов такси на следующий час на основе исторических данных. | `pandas`, `numpy`, `sklearn`, `matplotlib`, `seaborn`, `statsmodels`, `LightGBM`, `CatBoost` |
| 12| [Классификация токсичных комментариев (Викишоп)](#12-классификация-токсичных-комментариев-викишоп) | Обнаружение токсичных комментариев пользователей интернет-магазина. | `pandas`, `numpy`, `sklearn`, `CatBoost`, `LightGBM`, `transformers`, `torch`, `optuna`, `spacy` |
| 13 | [Определение возраста покупателей](#13-определение-возраста-покупателей) | Построение модели компьютерного зрения для оценки возраста человека по фотографии. | `pandas`, `numpy`, `tensorflow.keras`, `cv2`, `matplotlib` |
| 14 | [Прогноз оттока клиентов телеком-оператора (ТелеДом)](#15-прогноз-оттока-клиентов-телеком-оператора-теледом) | Обучение модели машинного обучения для предсказания оттока клиентов по данным об услугах и договорах. | `pandas`, `numpy`, `matplotlib`, `seaborn`, `sklearn`, `catboost`, `lightgbm` |


---

## Детальное описание проектов

### 1. Музыка больших городов

**Описание проекта:**
Сравнение предпочтений пользователей Яндекс.Музыки из Москвы и Санкт-Петербурга в зависимости от времени суток (утро и вечер) и дня недели (понедельник, среда, пятница).

**Используемые библиотеки:**
- `pandas`

---

### 2. Исследование надежности заемщиков

**Описание проекта:**
Проведение исследования банковских данных клиентов с целью выявления зависимостей между количеством детей и своевременным возвратом кредита, семейным положением и своевременным возвратом кредита, а также уровнем дохода и своевременным возвратом кредита.

**Используемые библиотеки:**
- `pandas`
- `matplotlib`

---

### 3. Исследование объявлений о продаже квартир

**Описание проекта:**
Анализ архивных данных Яндекс Недвижимость о продаже квартир в Санкт-Петербурге и соседних населённых пунктах за несколько лет. Цель проекта — определить рыночную стоимость объектов недвижимости посредством исследовательского анализа данных и установить параметры, влияющие на цену объектов. Также планируется построение автоматизированной системы для отслеживания аномалий и мошеннической деятельности.

**Описание данных:**
- **airports_nearest:** расстояние до ближайшего аэропорта (м)
- **balcony:** количество балконов
- **ceiling_height:** высота потолков (м)
- **cityCenters_nearest:** расстояние до центра города (м)
- **days_exposition:** количество дней размещения объявления
- **first_day_exposition:** дата публикации
- **floor:** этаж
- **floors_total:** всего этажей в доме
- **is_apartment:** апартаменты (булев тип)
- **kitchen_area:** площадь кухни (м²)
- **last_price:** цена на момент снятия с публикации
- **living_area:** жилая площадь (м²)
- **locality_name:** название населённого пункта
- **open_plan:** свободная планировка (булев тип)
- **parks_around3000:** количество парков в радиусе 3 км
- **parks_nearest:** расстояние до ближайшего парка (м)
- **ponds_around3000:** количество водоёмов в радиусе 3 км
- **ponds_nearest:** расстояние до ближайшего водоёма (м)
- **rooms:** количество комнат
- **studio:** квартира-студия (булев тип)
- **total_area:** общая площадь квартиры (м²)
- **total_images:** количество фотографий в объявлении

**Используемые библиотеки:**
- `pandas`
- `matplotlib`

---

### 4. Статистический анализ данных

**Описание проекта:**
Анализ данных о пользователях, их поездках и подписках для выявления ключевых тенденций и закономерностей.

**Описание данных:**
- **Пользователи (users_go.csv):**
  - `user_id`: уникальный идентификатор пользователя
  - `name`: имя пользователя
  - `age`: возраст
  - `city`: город
  - `subscription_type`: тип подписки (free, ultra)
- **Поездки (rides_go.csv):**
  - `user_id`: уникальный идентификатор пользователя
  - `distance`: расстояние, проеханное в текущей сессии (м)
  - `duration`: продолжительность сессии (мин)
  - `date`: дата поездки
- **Подписки (subscriptions_go.csv):**
  - `subscription_type`: тип подписки
  - `minute_price`: стоимость одной минуты поездки
  - `start_ride_price`: стоимость начала поездки
  - `subscription_fee`: ежемесячный платеж

**Используемые библиотеки:**
- `numpy`
- `pandas`
- `scipy`
- `matplotlib`

---

### 5. Анализ факторов успеха видеоигр

**Описание проекта:**
Выявление факторов, определяющих успешность видеоигр, для прогнозирования их популярности и планирования рекламных кампаний на 2017 год.

**Описание данных:**
- **Name:** название игры
- **Platform:** платформа
- **Year_of_Release:** год выпуска
- **Genre:** жанр игры
- **NA_sales:** продажи в Северной Америке (млн копий)
- **EU_sales:** продажи в Европе (млн копий)
- **JP_sales:** продажи в Японии (млн копий)
- **Other_sales:** продажи в других странах (млн копий)
- **Critic_Score:** оценка критиков (макс. 100)
- **User_Score:** оценка пользователей (макс. 10)
- **Rating:** рейтинг ESRB

**Используемые библиотеки:**
- `pandas`
- `matplotlib`
- `seaborn`
- `numpy`
- `scipy`

---

### 6. Прогнозная модель «ЭкоФерма» для отбора буренок

**Описание проекта:**
Разработка двух моделей:
1. Прогнозирование возможного удоя коровы (целевой признак: Удой).
2. Расчет вероятности получения вкусного молока от коровы (целевой признак: Вкус молока).

**Описание данных:**
- **ferma_main.csv:**
  - `id`: уникальный идентификатор коровы
  - `Удой, кг`: масса молока в год
  - `ЭКЕ`: энергетическая кормовая единица
  - `Сырой протеин, г`: содержание протеина в корме
  - `СПО`: соотношение сахара к протеину в корме
  - `Порода`: порода коровы
  - `Тип пастбища`: тип пастбища
  - `порода папы_быка`: порода папы коровы
  - `Жирность,%`: содержание жиров в молоке
  - `Белок,%`: содержание белков в молоке
  - `Вкус молока`: оценка вкуса (бинарный)
  - `Возраст`: возраст коровы (бинарный)
- **ferma_dad.csv:**
  - `id`: уникальный идентификатор коровы
  - `Имя Папы`: имя папы коровы
- **cow_buy.csv:**
  - `Порода`: порода коровы
  - `Тип пастбища`: тип пастбища
  - `порода папы_быка`: порода папы коровы
  - `Имя_папы`: имя папы коровы
  - `Текущая_жирность,%`: содержание жиров в молоке
  - `Текущий_уровень_белок,%`: содержание белков в молоке
  - `Возраст`: возраст коровы (бинарный)

**Используемые библиотеки:**
- `numpy`
- `pandas`
- `matplotlib`
- `seaborn`
- `sklearn`
- `statsmodels`

---

### 7. Персонализация предложений постоянным клиентам

**Описание проекта:**
Разработка решения для интернет-магазина «В один клик» с целью персонализации предложений постоянным клиентам для повышения их активности.

**Описание данных:**
- **market_file.csv:** данные о поведении покупателя на сайте.
- **market_money.csv:** данные о выручке от каждого покупателя.
- **market_time.csv:** данные о времени, проведенном на сайте.
- **money.csv:** данные о среднемесячной прибыли от покупателя.

**Используемые библиотеки:**
- `pandas`
- `numpy`
- `shap`
- `phik`
- `sklearn`
- `seaborn`
- `matplotlib`

---

### 8. Предсказание удовлетворенности сотрудников и их увольнения

**Описание проекта:**
Построение двух моделей:
1. Предсказание уровня удовлетворённости сотрудника на основе данных.
2. Предсказание вероятности увольнения сотрудника из компании.

**Описание данных:**
- `id`: уникальный идентификатор сотрудника
- `dept`: отдел
- `level`: уровень должности
- `workload`: уровень загруженности
- `employment_years`: стаж работы в компании
- `last_year_promo`: было ли повышение за последний год
- `last_year_violations`: были ли нарушения трудового договора
- `supervisor_evaluation`: оценка работы сотрудника руководителем
- `salary`: ежемесячная зарплата
- `job_satisfaction_rate`: уровень удовлетворённости (целевой признак)

**Используемые библиотеки:**
- `pandas`
- `numpy`
- `sklearn`
- `seaborn`
- `matplotlib`
- `phik`

---

### 9. Выбор локации для скважины

**Описание проекта:**
Разработка модели машинного обучения для предсказания объёма запасов нефти в скважинах и выбор региона для бурения на основе расчёта прибыли и оценки рисков с использованием метода Bootstrap.

**Этапы работы:**
1. **Подготовка данных:**
   - Загрузка и предобработка данных (удаление дубликатов, проверка пропущенных значений).
   - Разделение данных на обучающую и валидационную выборки.

2. **Обучение модели:**
   - Использование линейной регрессии для предсказания объёма запасов нефти.
   - Оценка модели с помощью RMSE.

3. **Расчёт прибыли:**
   - Выбор 200 лучших скважин в каждом регионе.
   - Расчёт общей прибыли с учётом стоимости добычи и цен на нефть.

4. **Анализ рисков:**
   - Использование метода Bootstrap для оценки распределения прибыли.
   - Определение 95%-го доверительного интервала прибыли.
   - Выбор региона с наименьшим риском и наибольшей средней прибылью.

**Описание данных:**
- `id` — уникальный идентификатор скважины.
- `f0`, `f1`, `f2` — признаки точки месторождения.
- `product` — объём запасов в скважине (тыс. баррелей).

**Условия задачи:**
- Линейная регрессия — единственная разрешённая модель.
- Исследуется 500 точек в регионе, выбираются 200 лучших.
- Бюджет на разработку: 10 млрд рублей.
- Цена за 1 баррель нефти: 450 рублей.
- Прибыльность оценивается с риском убытков < 2.5%.

**Результаты:**
- Средний запас нефти по регионам: от 92 до 137 тыс. баррелей.
- Средняя прибыль по регионам варьируется, но один регион демонстрирует наименьший риск убытков.
- Окончательное решение основано на наибольшей ожидаемой прибыли и минимальном риске.

**Используемые библиотеки:**
- `pandas`
- `numpy`
- `scikit-learn`
- `matplotlib`
- `seaborn`
- `scipy`

---

### 10. Определение стоимости автомобилей

**Описание проекта:**
Сервис по продаже автомобилей с пробегом «Не бит, не крашен» разрабатывает приложение для оценки рыночной стоимости автомобилей. В рамках проекта требуется разработать модель машинного обучения, способную предсказывать цену автомобиля на основе его характеристик.

**Ключевые требования заказчика:**
- Высокое качество предсказаний.
- Минимальное время обучения модели.
- Быстрое предсказание стоимости автомобиля.

**Этапы работы:**
1. **Загрузка и предобработка данных:**
   - Анализ данных, обработка пропущенных значений и аномалий.
   - Удаление неинформативных признаков.

2. **Формирование выборок:**
   - Разделение данных на обучающую, валидационную и тестовую выборки.

3. **Обучение и тестирование моделей:**
   - Обучение различных моделей машинного обучения (включая LightGBM и не-бустинговые модели).
   - Оптимизация гиперпараметров.
   - Оценка моделей по метрике RMSE.

4. **Сравнение моделей:**
   - Анализ качества предсказаний.
   - Сравнение времени обучения и скорости предсказания.

5. **Выбор лучшей модели:**
   - Финальное тестирование на тестовой выборке.
   - Оценка точности и скорости предсказаний.

**Описание данных:**
- `DateCrawled` — дата скачивания анкеты из базы.
- `VehicleType` — тип автомобильного кузова.
- `RegistrationYear` — год регистрации автомобиля.
- `Gearbox` — тип коробки передач.
- `Power` — мощность (л.с.).
- `Model` — модель автомобиля.
- `Kilometer` — пробег (км).
- `RegistrationMonth` — месяц регистрации автомобиля.
- `FuelType` — тип топлива.
- `Brand` — марка автомобиля.
- `Repaired` — была машина в ремонте или нет.
- `DateCreated` — дата создания анкеты.
- `NumberOfPictures` — количество фотографий автомобиля.
- `PostalCode` — почтовый индекс владельца анкеты.
- `LastSeen` — дата последней активности пользователя.

**Целевой признак:**
- `Price` — цена автомобиля (евро).

**Метрики оценки:**
- **Root Mean Squared Error (RMSE):** основной критерий качества предсказаний.
- Целевая метрика: RMSE < 2500.

**Результаты:**
- Определена наилучшая модель для предсказания цен автомобилей.
- Анализ скорости обучения и времени предсказаний позволил выбрать оптимальную модель.
- RMSE лучшей модели соответствует требованиям заказчика.

**Используемые библиотеки:**
- `pandas`
- `numpy`
- `matplotlib`
- `seaborn`
- `scikit-learn`
- `LightGBM`

---
### 11. Прогнозирование заказов такси

**Описание проекта:**
Компания «Чётенькое такси» собирает данные о заказах такси в аэропортах. Для привлечения большего числа водителей в периоды пиковой нагрузки необходимо построить модель прогнозирования количества заказов на следующий час.

**Ключевые требования заказчика:**
- Высокая точность предсказаний.
- Значение метрики RMSE на тестовой выборке не больше 48.

**Этапы работы:**
1. **Загрузка и предобработка данных:**
   - Ресемплирование данных с шагом в 1 час.
   - Анализ временного ряда на наличие трендов, сезонности и выбросов.

2. **Обучение моделей:**
   - Разделение данных на обучающую и тестовую выборки (10% данных в тесте).
   - Тестирование нескольких моделей: линейная регрессия, случайный лес, градиентный бустинг (LightGBM, CatBoost).
   - Оптимизация гиперпараметров для выбора наилучшей модели.

3. **Оценка модели:**
   - Оценка предсказаний с использованием метрики RMSE.
   - Анализ автокорреляции временного ряда (ACF, PACF).
   - Оценка значимости сезонных компонентов.

4. **Выбор оптимальной модели:**
   - Сравнение моделей по скорости предсказаний и точности.
   - Финальное тестирование на отложенной выборке.

**Описание данных:**
- **Данные находятся в файле:** `/taxi.csv`
- **Целевой признак:**
  - `num_orders` — количество заказов такси в данный час.

**Метрики оценки:**
- **Root Mean Squared Error (RMSE):** основной критерий качества предсказаний.
- **Целевая метрика:** RMSE < 48.

**Результаты:**
- Построена и протестирована модель прогнозирования спроса на такси.
- Оптимизированы гиперпараметры для улучшения точности.
- Выбрана лучшая модель, соответствующая требованиям заказчика.

**Используемые библиотеки:**
- `pandas`
- `numpy`
- `matplotlib`
- `seaborn`
- `scikit-learn`
- `statsmodels`
- `LightGBM`
- `CatBoost`
- `TimeSeriesSplit`
---
### 12. Классификация токсичных комментариев (Викишоп)

**Описание проекта:**

Интернет-магазин **«Викишоп»** запускает функциональность, позволяющую пользователям редактировать описания товаров. Пользователи могут оставлять правки и комментарии, включая токсичные высказывания. Задача — построить модель для классификации комментариев и автоматической отправки токсичных на модерацию.

**Цель:**
Построить модель бинарной классификации комментариев (токсичный/не токсичный) с метрикой **F1 ≥ 0.75**.

**Этапы проекта:**

1. **Загрузка и подготовка данных:**
   - Очистка текста от мусора (символы, пробелы, регистр).
   - Балансировка классов (upsampling / SMOTE).
   - Преобразование текста с помощью `TfidfVectorizer` и `CountVectorizer`.

2. **Обучение моделей:**
   - Логистическая регрессия
   - Decision Tree
   - CatBoostClassifier
   - LightGBMClassifier
   - VotingClassifier
   - Модель на основе трансформера **BERT (TFBertModel)**

3. **Оптимизация и кросс-валидация:**
   - `GridSearchCV`, `StratifiedKFold`, `Optuna`
   - Использование `F1-score` как основной метрики.

4. **Сравнение моделей:**
   - По точности (F1-score)
   - По времени обучения
   - По интерпретируемости результатов

**Описание данных:**

- `text` — текст комментария
- `toxic` — целевой признак (1 — токсичный, 0 — нет)

**Метрики оценки:**
- **F1-score** (цель: ≥ 0.75)

**Результаты:**
- Модели достигли F1 > 0.75
- BERT дал лучшие результаты, но требует больше ресурсов
- CatBoost и LightGBM показали конкурентоспособные результаты с высокой скоростью предсказания

**Используемые библиотеки:**

- `pandas`, `numpy`
- `matplotlib`, `seaborn`
- `sklearn`
- `CatBoost`, `LightGBM`
- `transformers`, `torch`, `TFBertModel`
- `optuna`, `spacy`, `tqdm`
- `imblearn` (SMOTE)

### 13. Определение возраста покупателей

**Описание проекта:**

Сетевой супермаркет **«Хлеб-Соль»** внедряет систему компьютерного зрения для обработки фотографий покупателей в прикассовой зоне. Цель проекта — построить модель, определяющую **возраст человека по его фотографии**. Это позволит:

- Предлагать товары, релевантные возрастной группе;
- Контролировать продажу алкоголя несовершеннолетним.

**Метрика качества:**  
- MAE (Mean Absolute Error) — средняя абсолютная ошибка.

**Этапы проекта:**

1. **Исследовательский анализ данных (EDA):**
   - Анализ распределения возрастов;
   - Проверка баланса классов и выявление выбросов;
   - Анализ размеров изображений, визуализация примеров.

2. **Подготовка данных:**
   - Использование `ImageDataGenerator` и метода `flow_from_dataframe`;
   - Нормализация пикселей, масштабирование изображений;
   - Разделение на обучающую и валидационную выборки.

3. **Обучение модели:**
   - Архитектура CNN с блоками свёрток, BatchNorm, Dropout, GlobalAveragePooling;
   - Аугментации: повороты, отражения, масштабирование;
   - Callbacks: EarlyStopping, ReduceLROnPlateau.

4. **Оценка и интерпретация:**
   - MAE < 8 — удовлетворительный результат;
   - Визуализация предсказаний модели и примеров ошибок.

**Описание данных:**

- **labels.csv:**
  - `file_name`: имя файла изображения;
  - `real_age`: возраст человека.
- **Папка изображений:** `/datasets/faces/final_files/`.

**Используемые библиотеки:**

- `pandas`, `numpy`
- `matplotlib`, `seaborn`
- `tensorflow.keras`
- `cv2`, `PIL`
- `sklearn.metrics` (`mean_absolute_error`)

**Результаты:**

- Модель успешно обучена на сверточной архитектуре с аугментациями;
- Средняя ошибка предсказания по возрасту составила менее 8 лет;
- Возможность дальнейшего улучшения модели с использованием предобученных сетей (например, ResNet, EfficientNet).

### 14. Прогноз оттока клиентов телеком-оператора (ТелеДом)

**Описание проекта:**

Оператор связи **«ТелеДом»** хочет сократить отток клиентов, предлагая им специальные условия до момента отказа от услуг. Для этого необходима модель, которая будет предсказывать вероятность расторжения договора. В распоряжении аналитика — объединённые данные о клиентах, тарифах и подключённых услугах.

**Цель:**
Обучить модель бинарной классификации, которая будет предсказывать, уйдёт ли клиент, на основе его профиля и истории услуг.

**Этапы проекта:**

1. **Загрузка данных:**
   - Чтение и первичный осмотр четырёх файлов: `contract_new.csv`, `personal_new.csv`, `internet_new.csv`, `phone_new.csv`.

2. **Исследовательский анализ и предобработка:**
   - Обработка пропусков, аномалий и категориальных признаков.
   - Приведение данных к единому типу, выявление признаков, требующих удаления или трансформации.

3. **Объединение данных:**
   - Слияние всех таблиц по признаку `customerID`.
   - Формирование итогового датафрейма с ключевыми признаками.

4. **Анализ и генерация признаков:**
   - Визуализация распределений, корреляционный анализ.
   - Генерация дополнительных признаков, потенциально улучшающих обучение.

5. **Подготовка к обучению:**
   - Кодирование категориальных переменных (`OneHotEncoder`, `LabelEncoder`);
   - Масштабирование числовых признаков;
   - Деление на обучающую, валидационную и тестовую выборки.

6. **Обучение моделей:**
   - Логистическая регрессия (baseline);
   - CatBoostClassifier;
   - LightGBMClassifier;
   - Подбор гиперпараметров с `GridSearchCV`.

7. **Оценка и выбор лучшей модели:**
   - Метрика: **F1-score**;
   - ROC-AUC, Precision, Recall, Confusion Matrix;
   - Окончательная проверка модели на тестовой выборке.

8. **Бизнес-выводы и рекомендации:**
   - Описание признаков, оказывающих наибольшее влияние на уход клиента;
   - Рекомендации по действиям с высокорисковыми группами (например, интернет-абоненты с fiber optic без OnlineSecurity и TechSupport);
   - Возможности внедрения модели в CRM для автотриггеров маркетинга.

**Описание данных:**

- **contract_new.csv:** информация о договорах (тип, расходы, дата начала/окончания);
- **personal_new.csv:** пол, возрастной статус, наличие партнёра/детей;
- **internet_new.csv:** тип подключения, подключённые интернет-сервисы;
- **phone_new.csv:** наличие подключения к нескольким линиям;
- Целевой признак: факт расторжения договора (`EndDate ≠ null`).

**Используемые библиотеки:**

- `pandas`, `numpy`
- `matplotlib`, `seaborn`
- `sklearn` (`LogisticRegression`, `GridSearchCV`, `classification_report`)
- `catboost`, `lightgbm`

**Результаты:**

- Построена модель с **F1-score > 0.84** на тестовой выборке.
- Выявлены ключевые факторы риска: месячные договоры, оплата paperless, отсутствие услуг OnlineSecurity и TechSupport.
- Модель рекомендована для внедрения в систему поддержки клиентов для снижения оттока.

---

## Навыки

- **Анализ данных**: `pandas`, `numpy`
- **Визуализация**: `matplotlib`, `seaborn`
- **Машинное обучение**: `scikit-learn`, `statsmodels`
- **Статистический анализ**: `scipy`
- **Моделирование и прогнозирование**
- **Работа с большими данными и их предобработка**
- **Работа с текстами (NLP)**: очистка, токенизация, векторизация
- **Оптимизация гиперпараметров**: GridSearchCV, Optuna
- **Работа с несбалансированными классами**
- **Модульная сборка ML pipeline**
- **Работа с BERT и трансформерами**

## Контакты
